{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26ee4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.10.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\angie\\hello_ai\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a73dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf21c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar su rendimiento en tareas específicas a partir de datos, sin ser programadas explícitamente para ello. Utiliza algoritmos para identificar patrones y hacer predicciones o decisiones basadas en la información proporcionada.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Primer paso: obtener una descripción\n",
    "primer_prompt = PromptTemplate(\n",
    "    input_variables=[\"tema\"],\n",
    "    template=\"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_chain = LLMChain(llm=llm, prompt=primer_prompt)\n",
    "\n",
    "# Segundo paso: generar aplicación educativa\n",
    "segundo_prompt = PromptTemplate(\n",
    "    input_variables=[\"concepto\"],\n",
    "    template=\"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_chain = LLMChain(llm=llm, prompt=segundo_prompt)\n",
    "\n",
    "# Combinar ambos pasos en una cadena secuencial\n",
    "chain_secuencial = SimpleSequentialChain(chains=[primer_chain, segundo_chain])\n",
    "\n",
    "# Ejecutar la cadena completa\n",
    "resultado = chain_secuencial.run(\"realidad aumentada\")\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36dbd0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicación Educativa: \"Aula Aumentada\"**\n",
      "\n",
      "**Descripción General:**\n",
      "\"Aula Aumentada\" es una aplicación educativa diseñada para enriquecer el aprendizaje en diversas materias a través de la realidad aumentada. La aplicación permite a los estudiantes interactuar con contenidos digitales relacionados con su entorno físico, facilitando una experiencia de aprendizaje más inmersiva y contextualizada.\n",
      "\n",
      "**Características de la Aplicación:**\n",
      "\n",
      "1. **Contenido Interactivo:**\n",
      "   - Los docentes pueden crear y cargar contenido educativo en la plataforma, como imágenes, videos, modelos 3D y cuestionarios interactivos que se superponen en el entorno real.\n",
      "   - Por ejemplo, en una clase de biología, los estudiantes pueden apuntar su dispositivo hacia una planta y ver información sobre su estructura celular, su ecosistema y su ciclo de vida.\n",
      "\n",
      "2. **Exploración del Entorno:**\n",
      "   - La aplicación utiliza la cámara del dispositivo para reconocer objetos y lugares. Al escanear un objeto específico, los estudiantes pueden acceder a información adicional, como videos explicativos, infografías o simulaciones interactivas.\n",
      "   - En una clase de historia, al escanear una imagen de un monumento, los estudiantes pueden ver una reconstrucción 3D y escuchar una narración sobre su historia.\n",
      "\n",
      "3. **Gamificación del Aprendizaje:**\n",
      "   - Se pueden incluir elementos de gamificación, como desafíos y recompensas, para fomentar la participación y el interés de los estudiantes.\n",
      "   - Por ejemplo, los estudiantes pueden completar misiones relacionadas con el contenido de la clase, como encontrar ciertos objetos en el aula que desencadenen información adicional en la aplicación.\n",
      "\n",
      "4. **Colaboración y Proyectos:**\n",
      "   - Los estudiantes pueden trabajar en grupos para crear sus propios proyectos utilizando la aplicación, permitiéndoles investigar y presentar temas de manera creativa.\n",
      "   - Pueden combinar sus investigaciones en un solo proyecto de RA que se presente en el aula, donde sus compañeros puedan interactuar con su trabajo.\n",
      "\n",
      "5. **Accesibilidad y Personalización:**\n",
      "   - La aplicación puede ser diseñada para adaptarse a diferentes niveles educativos y estilos de aprendizaje, permitiendo que los docentes personalicen el contenido según las necesidades de sus estudiantes.\n",
      "   - También puede incluir opciones de accesibilidad para estudiantes con discapacidades, como descripciones de audio y subtítulos.\n",
      "\n",
      "**Beneficios:**\n",
      "- Fomenta un aprendizaje activo y participativo.\n",
      "- Mejora la retención de información al conectar conceptos abstractos con el mundo real.\n",
      "- Desarrolla habilidades tecnológicas y de investigación en los estudiantes.\n",
      "- Promueve la colaboración y el trabajo en equipo.\n",
      "\n",
      "**Implementación:**\n",
      "Para implementar \"Aula Aumentada\", las escuelas necesitarían dispositivos compatibles con la aplicación (smartphones o tabletas) y formación para los docentes sobre cómo integrar la RA en su enseñanza. Además, se pueden crear alianzas con instituciones educativas y desarrolladores de contenido para enriquecer la base de datos de la aplicación.\n",
      "\n",
      "En resumen, \"Aula Aumentada\" transforma el aprendizaje tradicional al aprovechar la tecnología de la realidad aumentada, haciendo que el conocimiento sea más accesible, interactivo y emocionante para los estudiantes.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e55bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! ¿En qué puedo ayudarte hoy con respecto a la enseñanza de informática?\n",
      "Claro, aquí tienes algunos pasos para introducir la inteligencia artificial (IA) a tus estudiantes:\n",
      "\n",
      "1. **Conceptos Básicos**:\n",
      "   - Comienza explicando qué es la IA: la capacidad de una máquina para imitar la inteligencia humana.\n",
      "   - Presenta términos clave como aprendizaje automático, redes neuronales y procesamiento del lenguaje natural.\n",
      "\n",
      "2. **Historia y Aplicaciones**:\n",
      "   - Proporciona una breve historia de la IA y sus hitos importantes.\n",
      "   - Muestra aplicaciones prácticas en la vida cotidiana, como asistentes virtuales (Siri, Alexa), recomendaciones de productos y reconocimiento facial.\n",
      "\n",
      "3. **Demostraciones Prácticas**:\n",
      "   - Usa herramientas y plataformas accesibles como Google Teachable Machine o Scratch para mostrar cómo funciona el aprendizaje automático.\n",
      "   - Realiza proyectos simples donde los estudiantes puedan crear modelos básicos de IA.\n",
      "\n",
      "4. **Ética y Consideraciones**:\n",
      "   - Discute los aspectos éticos de la IA, como la privacidad, el sesgo y el impacto en el empleo.\n",
      "   - Fomenta el pensamiento crítico sobre cómo se utiliza la IA en la sociedad.\n",
      "\n",
      "5. **Proyectos y Actividades**:\n",
      "   - Asigna proyectos donde los estudiantes puedan aplicar lo aprendido, como crear un chatbot simple o un sistema de recomendación.\n",
      "   - Organiza debates sobre el futuro de la IA y sus implicaciones.\n",
      "\n",
      "6. **Recursos Adicionales**:\n",
      "   - Proporciona recursos en línea, como cursos gratuitos (Coursera, edX) y tutoriales de YouTube, para que los estudiantes profundicen en el tema.\n",
      "\n",
      "Recuerda adaptar el contenido según el nivel de tus estudiantes y fomentar un ambiente de curiosidad y exploración. ¡Buena suerte!\n",
      "Aquí tienes algunos ejemplos prácticos que puedes usar en clase para enseñar inteligencia artificial:\n",
      "\n",
      "1. **Chatbots**:\n",
      "   - **Actividad**: Crea un chatbot simple usando plataformas como Chatbot.com o Dialogflow. Los estudiantes pueden diseñar un bot que responda preguntas sobre un tema específico.\n",
      "   - **Objetivo**: Entender el procesamiento del lenguaje natural y la interacción humano-máquina.\n",
      "\n",
      "2. **Clasificación de Imágenes**:\n",
      "   - **Actividad**: Utiliza Google Teachable Machine para que los estudiantes entrenen un modelo que clasifique imágenes (por ejemplo, distinguir entre diferentes tipos de frutas).\n",
      "   - **Objetivo**: Aprender sobre redes neuronales y cómo las máquinas pueden aprender a partir de datos visuales.\n",
      "\n",
      "3. **Reconocimiento de Voz**:\n",
      "   - **Actividad**: Implementa un proyecto simple usando herramientas como Voiceflow o la API de Google Cloud Speech-to-Text para crear una aplicación que reconozca comandos de voz.\n",
      "   - **Objetivo**: Explorar el reconocimiento de voz y su aplicación en asistentes virtuales.\n",
      "\n",
      "4. **Recomendaciones de Contenido**:\n",
      "   - **Actividad**: Analiza cómo funcionan los sistemas de recomendación (como los de Netflix o Spotify) y haz que los estudiantes creen un sistema básico utilizando datos ficticios.\n",
      "   - **Objetivo**: Comprender el filtrado colaborativo y el aprendizaje automático.\n",
      "\n",
      "5. **Análisis de Sentimientos**:\n",
      "   - **Actividad**: Usa herramientas como MonkeyLearn o TextBlob para que los estudiantes analicen textos y determinen el sentimiento (positivo, negativo o neutral) de reseñas de productos.\n",
      "   - **Objetivo**: Aprender sobre el procesamiento del lenguaje natural y su aplicación en el análisis de datos.\n",
      "\n",
      "6. **Juegos con IA**:\n",
      "   - **Actividad**: Jugar a juegos como \"AI Dungeon\" donde la IA genera historias interactivas y los estudiantes pueden influir en el desarrollo de la narrativa.\n",
      "   - **Objetivo**: Ver cómo la IA puede ser creativa y generar contenido dinámico.\n",
      "\n",
      "7. **Proyectos de Robótica**:\n",
      "   - **Actividad**: Si tienes acceso a kits de robótica (como LEGO Mindstorms o Arduino), los estudiantes pueden programar un robot para que siga líneas o evite obstáculos.\n",
      "   - **Objetivo**: Integrar IA en la robótica y entender la toma de decisiones basada en datos sensoriales.\n",
      "\n",
      "Estos ejemplos no solo son prácticos, sino que también fomentan el aprendizaje activo y la colaboración entre los estudiantes. ¡Espero que te sean útiles!\n"
     ]
    }
   ],
   "source": [
    "# Instalar si hace falta:\n",
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de informática.\"))\n",
    "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
